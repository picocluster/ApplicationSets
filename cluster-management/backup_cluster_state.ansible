---
# Automated Backup of PicoCluster State
#
# Backs up critical cluster configuration and data:
# - Prometheus configuration and data
# - Grafana dashboards and configuration
# - Consul service discovery state
# - Kubernetes configuration (if K3s/K8s installed)
# - Node configuration files
# - System SSH keys
#
# Backup location: /backups/picocluster-backup-<timestamp>.tar.gz
# Retention: 7 day rolling backup (adjust BACKUP_RETENTION)
#
# Usage:
#   # Full cluster backup
#   ansible-playbook cluster-management/backup_cluster_state.ansible
#
#   # Backup specific components
#   ansible-playbook cluster-management/backup_cluster_state.ansible \
#     -e backup_components="prometheus,grafana"
#
#   # Backup to external location
#   ansible-playbook cluster-management/backup_cluster_state.ansible \
#     -e backup_destination="/mnt/nfs/backups"
#
# Restore:
#   # Extract backup
#   tar -xzf picocluster-backup-<timestamp>.tar.gz -C /
#
#   # Or restore specific component
#   tar -xzf picocluster-backup-<timestamp>.tar.gz -C / --wildcards "etc/prometheus/*"

- hosts: all
  gather_facts: yes
  become: yes

  vars:
    backup_base_dir: "/backups"
    backup_timestamp: "{{ ansible_date_time.iso8601_basic_short }}"
    backup_destination: "{{ backup_destination | default(backup_base_dir) }}"
    backup_retention_days: 7
    # Components to backup (comma-separated or list)
    backup_components: "{{ backup_components | default('prometheus,grafana,consul,kubernetes,ssh-keys,node-config') }}"

  pre_tasks:
    - name: Display backup information
      debug:
        msg: |
          ====== PicoCluster Backup ======

          Backup Timestamp: {{ backup_timestamp }}
          Backup Destination: {{ backup_destination }}
          Backup Retention: {{ backup_retention_days }} days
          Hostname: {{ ansible_hostname }}

          Components to backup:
          {{ backup_components }}

          ================================

    - name: Create backup directory
      file:
        path: "{{ backup_destination }}"
        state: directory
        mode: '0755'

  tasks:
    # Prometheus backup (on monitoring node)
    - name: Backup Prometheus
      block:
        - name: Create Prometheus backup directory
          file:
            path: "{{ backup_destination }}/prometheus-backup-{{ backup_timestamp }}"
            state: directory
            mode: '0755'

        - name: Backup Prometheus configuration
          shell: |
            tar -czf "{{ backup_destination }}/prometheus-backup-{{ backup_timestamp }}.tar.gz" \
              /etc/prometheus/ \
              --exclude="/etc/prometheus/node_sd.json" \
              2>/dev/null
          changed_when: false

        - name: Backup Prometheus data (last 7 days)
          shell: |
            find /var/lib/prometheus -mtime -7 -type f | \
            tar -czf "{{ backup_destination }}/prometheus-data-{{ backup_timestamp }}.tar.gz" \
              -T - 2>/dev/null || echo "No recent data"
          changed_when: false

      when:
        - inventory_hostname in groups.get('monitoring', [])
        - "'prometheus' in backup_components"
      ignore_errors: yes

    # Grafana backup (on monitoring node)
    - name: Backup Grafana
      block:
        - name: Backup Grafana configuration
          shell: |
            tar -czf "{{ backup_destination }}/grafana-backup-{{ backup_timestamp }}.tar.gz" \
              /etc/grafana/ \
              /var/lib/grafana/grafana.db \
              2>/dev/null || echo "Partial backup"
          changed_when: false

        - name: Export Grafana dashboards
          shell: |
            mkdir -p "{{ backup_destination }}/grafana-dashboards-{{ backup_timestamp }}"
            cd "{{ backup_destination }}/grafana-dashboards-{{ backup_timestamp }}"

            # Get list of dashboard IDs
            curl -s http://localhost:3000/api/search -H "Accept: application/json" 2>/dev/null | \
            jq -r '.[] | .id' | while read id; do
              curl -s http://localhost:3000/api/dashboards/uid/\$id \
                -H "Accept: application/json" \
                -o "dashboard-\${id}.json" 2>/dev/null || true
            done

            # Tar the exports
            tar -czf "{{ backup_destination }}/grafana-dashboards-{{ backup_timestamp }}.tar.gz" . 2>/dev/null
          changed_when: false
          ignore_errors: yes

      when:
        - inventory_hostname in groups.get('monitoring', [])
        - "'grafana' in backup_components"
      ignore_errors: yes

    # Consul backup (if running)
    - name: Backup Consul
      block:
        - name: Backup Consul state
          shell: |
            consul snapshot save "{{ backup_destination }}/consul-snapshot-{{ backup_timestamp }}.snap" 2>/dev/null
          changed_when: false

      when:
        - "'consul' in backup_components"
      ignore_errors: yes

    # Kubernetes backup (if K3s/K8s running)
    - name: Backup Kubernetes
      block:
        - name: Backup K3s configuration
          shell: |
            tar -czf "{{ backup_destination }}/k3s-backup-{{ backup_timestamp }}.tar.gz" \
              /etc/rancher/k3s/ \
              /var/lib/rancher/k3s/server/ \
              --exclude="/var/lib/rancher/k3s/server/logs" \
              --exclude="/var/lib/rancher/k3s/server/db/state.db" \
              2>/dev/null || echo "K3s backup failed"
          changed_when: false

        - name: Backup Kubernetes manifests
          shell: |
            mkdir -p "{{ backup_destination }}/k8s-manifests-{{ backup_timestamp }}"

            # Get all resources
            for ns in $(kubectl get namespace -o name 2>/dev/null | cut -d/ -f2); do
              kubectl get all -n \$ns -o yaml > "{{ backup_destination }}/k8s-manifests-{{ backup_timestamp }}/\${ns}.yaml" 2>/dev/null || true
            done

            # Tar manifests
            tar -czf "{{ backup_destination }}/k8s-manifests-{{ backup_timestamp }}.tar.gz" \
              "{{ backup_destination }}/k8s-manifests-{{ backup_timestamp }}/" 2>/dev/null || true
          changed_when: false

      when:
        - "'kubernetes' in backup_components"
      ignore_errors: yes

    # SSH keys backup (all nodes)
    - name: Backup SSH Keys
      block:
        - name: Backup SSH keys
          shell: |
            tar -czf "{{ backup_destination }}/ssh-keys-{{ ansible_hostname }}-{{ backup_timestamp }}.tar.gz" \
              /etc/ssh/ssh_host_* \
              /root/.ssh/ \
              --exclude="/root/.ssh/authorized_keys" \
              2>/dev/null || echo "SSH backup failed"
          changed_when: false

      when: "'ssh-keys' in backup_components"

    # Node configuration backup (all nodes)
    - name: Backup Node Configuration
      block:
        - name: Backup critical system files
          shell: |
            tar -czf "{{ backup_destination }}/node-config-{{ ansible_hostname }}-{{ backup_timestamp }}.tar.gz" \
              /etc/hostname \
              /etc/hosts \
              /etc/resolv.conf \
              /etc/network* \
              /etc/netplan* \
              /etc/NetworkManager* \
              /etc/fstab \
              /etc/sudoers \
              /etc/sudoers.d/ \
              /etc/systemd/system/ \
              --exclude="/etc/systemd/system-generators" \
              2>/dev/null || echo "Config backup partial"
          changed_when: false

      when: "'node-config' in backup_components"

  post_tasks:
    - name: List backup files (monitoring node)
      shell: "ls -lh {{ backup_destination }}/picocluster-backup-*.tar.gz 2>/dev/null | tail -10"
      register: backup_list
      changed_when: false
      when: inventory_hostname in groups.get('monitoring', [])

    - name: Display backup files
      debug:
        msg: "{{ backup_list.stdout }}"
      when: inventory_hostname in groups.get('monitoring', [])

    - name: Clean up old backups
      block:
        - name: Remove backups older than retention period
          shell: |
            find "{{ backup_destination }}" -name "*.tar.gz" -type f -mtime +{{ backup_retention_days }} -delete
            find "{{ backup_destination }}" -name "*.snap" -type f -mtime +{{ backup_retention_days }} -delete
          changed_when: false

        - name: List current backups
          shell: "ls -lh {{ backup_destination }}/*.tar.gz {{ backup_destination }}/*.snap 2>/dev/null | wc -l"
          register: backup_count
          changed_when: false

      when: inventory_hostname in groups.get('monitoring', [])

    - name: Display backup summary
      debug:
        msg: |
          ====== Backup Summary ======

          Backup Components:
          {{ backup_components }}

          Backup Location: {{ backup_destination }}
          Timestamp: {{ backup_timestamp }}
          Retention Days: {{ backup_retention_days }}
          Current Backups: {{ backup_count.stdout if backup_count.stdout is defined else 'N/A' }}

          Backup Files Created on {{ ansible_hostname }}:
          ─────────────────────────────────────────
          {% if 'prometheus' in backup_components and inventory_hostname in groups.get('monitoring', []) %}
          • prometheus-backup-{{ backup_timestamp }}.tar.gz
          • prometheus-data-{{ backup_timestamp }}.tar.gz
          {% endif %}
          {% if 'grafana' in backup_components and inventory_hostname in groups.get('monitoring', []) %}
          • grafana-backup-{{ backup_timestamp }}.tar.gz
          • grafana-dashboards-{{ backup_timestamp }}.tar.gz
          {% endif %}
          {% if 'consul' in backup_components %}
          • consul-snapshot-{{ backup_timestamp }}.snap
          {% endif %}
          {% if 'kubernetes' in backup_components %}
          • k3s-backup-{{ backup_timestamp }}.tar.gz
          • k8s-manifests-{{ backup_timestamp }}.tar.gz
          {% endif %}
          {% if 'ssh-keys' in backup_components %}
          • ssh-keys-{{ ansible_hostname }}-{{ backup_timestamp }}.tar.gz
          {% endif %}
          {% if 'node-config' in backup_components %}
          • node-config-{{ ansible_hostname }}-{{ backup_timestamp }}.tar.gz
          {% endif %}

          Restore Instructions:
          ─────────────────────────────────────────
          # Full restore
          tar -xzf {{ backup_destination }}/prometheus-backup-{{ backup_timestamp }}.tar.gz -C /

          # Restore specific files
          tar -xzf {{ backup_destination }}/grafana-backup-{{ backup_timestamp }}.tar.gz -C / --wildcards "etc/grafana/*"

          # Consul restore
          consul snapshot restore {{ backup_destination }}/consul-snapshot-{{ backup_timestamp }}.snap

          Backup Verification:
          ─────────────────────────────────────────
          # Test backup integrity
          tar -tzf {{ backup_destination }}/prometheus-backup-{{ backup_timestamp }}.tar.gz > /dev/null && echo "✓ Backup valid"

          Next Steps:
          ─────────────────────────────────────────
          1. Verify backup files on external storage
          2. Test restore on backup/test system
          3. Schedule automated daily backups (cron)
          4. Monitor backup disk usage

          ============================

    - name: Copy backups summary to file
      copy:
        content: |
          PicoCluster Backup Summary
          Generated: {{ ansible_date_time.iso8601 }}

          Backup Timestamp: {{ backup_timestamp }}
          Backup Location: {{ backup_destination }}
          Retention Period: {{ backup_retention_days }} days

          Components Backed Up:
          {{ backup_components }}

          Backup Files:
          {% if backup_list.stdout is defined %}
          {{ backup_list.stdout }}
          {% endif %}

          Restore Command:
          tar -xzf {{ backup_destination }}/{{ backup_components | split(',') | first }}-backup-{{ backup_timestamp }}.tar.gz -C /

          For detailed restore instructions, see BACKUP_GUIDE.md
        dest: "{{ backup_destination }}/BACKUP-{{ backup_timestamp }}-README.txt"
        owner: root
        group: root
        mode: '0644'
      when: inventory_hostname in groups.get('monitoring', [])
